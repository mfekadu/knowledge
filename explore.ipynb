{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/bin/pip\n",
      "\n",
      "/usr/bin/python\n",
      "\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/bin/python3\n",
      "\n",
      "/bin/sh: /Library/Frameworks/Python.framework/Versions/3.7/bin/spacy: Permission denied\n"
     ]
    }
   ],
   "source": [
    "!which pip # expect pip to be inside .../Versions/3.x/bin/pip\n",
    "!echo\n",
    "!which python\n",
    "!echo\n",
    "!which python3 # make sure python3 is a thing\n",
    "!echo\n",
    "!spacy # make sure spacy is a thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (2.1.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy) (0.2.2)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy) (1.16.3)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy) (0.0.7)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy) (7.0.8)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy) (0.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy) (2.21.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from thinc<7.1.0,>=7.0.8->spacy) (4.32.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.3.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (2.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load English tokenizer, tagger, parser, NER and word vectors\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # Process whole documents\n",
    "# text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "#         \"Google in 2007, few people outside of the company took him \"\n",
    "#         \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "#         \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "#         \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "#         \"this week.\")\n",
    "# doc = nlp(text)\n",
    "\n",
    "# tok = doc[0]\n",
    "\n",
    "# # https://spacy.io/api/token\n",
    "\n",
    "# print(tok)\n",
    "\n",
    "# print(\"doc\",[(token.text, token.is_stop) for token in doc if not token.is_stop or not token.is_punct])\n",
    "\n",
    "# # Analyze syntax\n",
    "# print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "# print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n",
    "# # Find named entities, phrases and concepts\n",
    "# for entity in doc.ents:\n",
    "#     print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR:\t ['words.csv', 'speeches', 'README.md', 'index.csv']\n",
      "SPEECH_DIR[:2]:\t ['Minnesota_SOTS.txt', 'Indiana_SOTS.txt']\n",
      "TABLE_PATH:\t state-of-the-state/index.csv\n",
      "SPEECH_DIR:\t state-of-the-state/speeches\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"state-of-the-state\"\n",
    "FILENAME = \"index.csv\"\n",
    "SPEECH_DIR_NAME = \"speeches\"\n",
    "TABLE_PATH = os.path.join(DATA_DIR, FILENAME)\n",
    "SPEECH_DIR = os.path.join(DATA_DIR, SPEECH_DIR_NAME)\n",
    "print(\"DATA_DIR:\\t\", os.listdir(DATA_DIR))\n",
    "print(\"SPEECH_DIR[:2]:\\t\", os.listdir(SPEECH_DIR)[:2])\n",
    "print(\"TABLE_PATH:\\t\", TABLE_PATH)\n",
    "print(\"SPEECH_DIR:\\t\", SPEECH_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>governor</th>\n",
       "      <th>party</th>\n",
       "      <th>filename</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Kay Ivey</td>\n",
       "      <td>R</td>\n",
       "      <td>Alabama_SOTS.txt</td>\n",
       "      <td>https://governor.alabama.gov/remarks-speeches/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Mike Dunleavy</td>\n",
       "      <td>R</td>\n",
       "      <td>Alaska_SOTS.txt</td>\n",
       "      <td>https://gov.alaska.gov/newsroom/2019/01/22/201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Doug Ducey</td>\n",
       "      <td>R</td>\n",
       "      <td>Arizona_SOTS.txt</td>\n",
       "      <td>https://azgovernor.gov/governor/news/2019/01/g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Asa Hutchinson</td>\n",
       "      <td>R</td>\n",
       "      <td>Arkansas_SOTS.txt</td>\n",
       "      <td>https://governor.arkansas.gov/news-media/speec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>Gavin Newsom</td>\n",
       "      <td>D</td>\n",
       "      <td>California_SOTS.txt</td>\n",
       "      <td>https://www.gov.ca.gov/2019/02/12/state-of-the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state        governor party             filename  \\\n",
       "0     Alabama        Kay Ivey     R     Alabama_SOTS.txt   \n",
       "1      Alaska   Mike Dunleavy     R      Alaska_SOTS.txt   \n",
       "2     Arizona      Doug Ducey     R     Arizona_SOTS.txt   \n",
       "3    Arkansas  Asa Hutchinson     R    Arkansas_SOTS.txt   \n",
       "4  California    Gavin Newsom     D  California_SOTS.txt   \n",
       "\n",
       "                                                 url  \n",
       "0  https://governor.alabama.gov/remarks-speeches/...  \n",
       "1  https://gov.alaska.gov/newsroom/2019/01/22/201...  \n",
       "2  https://azgovernor.gov/governor/news/2019/01/g...  \n",
       "3  https://governor.arkansas.gov/news-media/speec...  \n",
       "4  https://www.gov.ca.gov/2019/02/12/state-of-the...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv for info on the data\n",
    "df = pd.read_csv(TABLE_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary mapping filenames to text content\n",
    "speech_map = {}\n",
    "\n",
    "# read the files\n",
    "for fname in df['filename'].get_values():\n",
    "    with open( os.path.join(SPEECH_DIR, fname) ) as f:\n",
    "        speech_map[fname] = f.read()\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spacy.io/api/span#set_extension\n",
    "# extend Span object with is_stop\n",
    "from spacy.tokens import Span\n",
    "\n",
    "# if the length is 1 and the word is a stopword\n",
    "stopword_checker_for_span = lambda span: (len(span) == 1 and type(span[0]).__name__ == \"Token\" and span[0].is_stop)\n",
    "Span.set_extension(\"is_stop\", getter=stopword_checker_for_span)\n",
    "\n",
    "# test ._.is_stop\n",
    "assert(nlp(\"I\")[:]._.is_stop == True)\n",
    "assert(nlp(\"Hello world\")[:]._.is_stop == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got noun chunks for Alabama_SOTS.txt\n",
      "got noun chunks for Alaska_SOTS.txt\n",
      "got noun chunks for Arizona_SOTS.txt\n",
      "got noun chunks for Arkansas_SOTS.txt\n",
      "got noun chunks for California_SOTS.txt\n",
      "got noun chunks for Colorado_SOTS.txt\n",
      "got noun chunks for Connecticut_SOTS.txt\n",
      "got noun chunks for Delaware_SOTS.txt\n",
      "got noun chunks for Florida_SOTS.txt\n",
      "got noun chunks for Georgia_SOTS.txt\n",
      "got noun chunks for Hawaii_SOTS.txt\n",
      "got noun chunks for Idaho_SOTS.txt\n",
      "got noun chunks for Illinois_Both.txt\n",
      "got noun chunks for Indiana_SOTS.txt\n",
      "got noun chunks for Iowa_SOTS.txt\n",
      "got noun chunks for Kansas_SOTS.txt\n",
      "got noun chunks for Kentucky_SOTS.txt\n",
      "got noun chunks for Louisiana_SOTS.txt\n",
      "got noun chunks for Maine_SOTS.txt\n",
      "got noun chunks for Maryland_SOTS.txt\n",
      "got noun chunks for Massachusetts_Both.txt\n",
      "got noun chunks for Michigan_SOTS.txt\n",
      "got noun chunks for Minnesota_SOTS.txt\n",
      "got noun chunks for Mississippi_SOTS.txt\n",
      "got noun chunks for Missouri_SOTS.txt\n",
      "got noun chunks for Montana_SOTS.txt\n",
      "got noun chunks for Nebraska_SOTS.txt\n",
      "got noun chunks for Nevada_SOTS.txt\n",
      "got noun chunks for NewHampshire_Both.txt\n",
      "got noun chunks for NewJersey_SOTS.txt\n",
      "got noun chunks for NewMexico_SOTS.txt\n",
      "got noun chunks for NewYork_SOTS.txt\n",
      "got noun chunks for NorthCarolina_SOTS.txt\n",
      "got noun chunks for NorthDakota_SOTS.txt\n",
      "got noun chunks for Ohio_SOTS.txt\n",
      "got noun chunks for Oklahoma_SOTS.txt\n",
      "got noun chunks for Oregon_Both.txt\n",
      "got noun chunks for Pennsylvania_SOTS.txt\n",
      "got noun chunks for RhodeIsland_SOTS.txt\n",
      "got noun chunks for SouthCarolina_SOTS.txt\n",
      "got noun chunks for SouthDakota_SOTS.txt\n",
      "got noun chunks for Tennessee_SOTS.txt\n",
      "got noun chunks for Texas_SOTS.txt\n",
      "got noun chunks for Utah_SOTS.txt\n",
      "got noun chunks for Vermont_Both.txt\n",
      "got noun chunks for Virginia_SOTS.txt\n",
      "got noun chunks for Washington_SOTS.txt\n",
      "got noun chunks for WestVirginia_SOTS.txt\n",
      "got noun chunks for Wisconsin_SOTS.txt\n",
      "got noun chunks for Wyoming_SOTS.txt\n"
     ]
    }
   ],
   "source": [
    "# https://spacy.io/usage/linguistic-features#noun-chunks\n",
    "\n",
    "speech_entity_map = {}\n",
    "\n",
    "for state in speech_map:\n",
    "    doc = nlp(speech_map[state])\n",
    "\n",
    "    entities = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if (not chunk._.is_stop): # e.g. if chunk != [\"it\"]\n",
    "            entities.append(chunk.text)\n",
    "#         # uncomment else block to debug and expect the printouts to look like stopwords\n",
    "#         else: \n",
    "#             print(type(chunk), chunk[0], type(chunk[0]), chunk.text)\n",
    "    print(f\"got noun chunks for {state}\")\n",
    "    speech_entity_map[state] = entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lieutenant Governor Ainsworth', 'Pro Tempore Marsh', 'Speaker McCutcheon', 'Speaker Pro Tempore Gaston', 'members', 'the Alabama Legislature', 'Chief Justice Parker', 'justices', 'the Alabama Supreme Court', 'my fellow Alabamians', 'Mother Nature', '’s', 'the form', 'our state', 'significant devastation', 'At least 23 innocent lives', 'Young children', 'life', 'Mothers', 'Fathers', 'Friends', 'neighbors', 'times', 'the good Lord', 'His continued comfort', 'healing hands', 'special thanks', 'the emergency responders', 'local law enforcement', 'a moment', 'silence', 'many others', 'uncertainty', 'what tomorrow', 'absolute certainty', 'the resiliency', 'the people', 'Alabama', 'a time', 'our entire nation', 'these good people', 'Lee County', 'its feet', 'our 200 years', 'statehood', 'the men', 'women', 'Alabama', 'our nation', 'our country', 'defending', 'the legendary Tuskegee Airmen', 'our country', 'injustice', 'an Alabama woman', 'her seat', 'a bus', 'our country', 'man', 'the moon', 'Alabamians', 'the rocket', 'The people', 'our state', 'the past', 'the present', 'a doubt', 'the forefront', 'our future', 'this occasion', 'our story', 'Alabama', 'one major accomplishment', 'the same time', 'state government', 'the hard-earned dollars', 'the men', 'women', 'this state', 'the state', 'our state', '’s', 'the willing attitude', 'the Chamber', 'our quest', 'our long-neglected issues', 'even greater prosperity', 'the entire state', 'Alabama', 'our time', 'Alabama’s economy', 'records', 'Alabama', 'a historic total', '$8.8 billion dollars', 'new capital investments', 'more than 17,000 new and future jobs', 'our people', 'Major technology companies', 'Amazon', 'Facebook', 'Google', 'Shipt', 'the rest', 'the country', 'business', 'our state', 'Alabama', 'track', 'the number two auto-producing state', 'the nation', 'less than five years', 'a state', 'a single car', 'truck', 'SUV', 'Our aerospace industry', 'the futures', 'both our state', 'nation', 'the recent groundbreaking', 'Airbus’s second assembly line', 'the City', 'Mobile', 'the top four cities', 'the world', 'aerospace manufacturing', 'Huntsville', 'construction', 'Blue Origin', '’s', 'Alabama’s', 'critical role', 'the United States', 'the forefront', 'space exploration', 'Alabama', 'a powerhouse', 'the automotive and aerospace industries', 'our Department', 'Commerce', 'the direction', 'Secretary Greg Canfield', 'project activity', 'areas', 'technology', 'forestry', 'bioscience', 'the Legislature', 'companies', 'the globe', 'the gold standard', 'Alabama', 'no mistake', 'The upward trend', 'Alabama’s economy', 'a direct compliment', 'the men', 'women', 'Alabama’s', 'These very men', 'women', 'hope', 'the good-paying jobs', 'our state', 'The Department', 'Labor', 'the capable leadership', 'Secretary Fitzgerald Washington', 'our vision', 'every Alabamian', 'a job', 'a job', 'Alabama', 'a record-breaking year', 'the lowest unemployment rate', 'our history', 'That’s', 'a record', 'our state', 'December', 'Alabama', 'the most people', 'our state', '49,000 more Alabamians', 'That’s', 'a record', 'our state', 'economists', '27,000 jobs', 'natural Alabama fashion', 'that projection', 'more than 44,000 additional jobs', 'a record', 'our state', 'some 80,000 Alabamians', 'employment opportunities', 'our state', 'faith', 'our efforts', 'their own individual situation', 'every Alabamian', 'an opportunity', 'their family', 'the ladder', 'success', 'our citizens', 'Alabama', 'maximum participation', 'the upcoming 2020 Census', 'the Alabama Counts campaign', 'the goal', 'much-needed federal funds', 'our state', 'the same time', 'our representation', 'Congress', 'Alabamians', 'the next decade', 'the hardworking men', 'women', 'Alabama', 'the Ivey Administration', 'Republican leadership', 'the past few years', 'the people', 'Alabama', 'major gains', 'significant growth', 'our economy', 'taxes', 'middle-class families', 'government', 'people', 'the past few years', 'more than 300 obsolete laws', 'regulations', 'the number', 'state employees', 'more than 6,000 people', 'the approach', 'Republican leadership', 'Alabama', 'literally hundreds of millions', 'dollars', 'every dollar', 'the government', 'the hardworking men', 'women', 'our state', 'law', 'the largest tax break', 'middle-class Alabamians', 'more than a decade', 'turn', 'the total impact', 'net $40 million dollars', 'savings', 'our taxpayers', 'the next decade', 'our efforts', 'the people', 'our state', 'their hard-earned dollars', 'our people', 'every Alabamian', 'the opportunity', 'a quality education', 'Strong Start', 'important strides', 'Alabama’s education system', 'a child', 'their fullest potential', 'life', 'a strong educational foundation', 'the nationally-recognized leadership', 'Secretary Jeana Ross', 'the tremendous efforts', 'the Department', 'Early Childhood Education', 'Alabama’s First Class Pre-K', 'the nation’s highest quality program', 'the 12th consecutive year', 'our efforts', 'Alabama’s children', 'a strong start', 'funding', '$18.5 million dollars', 'the largest, single-year increase', 'that historic investment', '107 new First Class Pre-K classrooms', 'Alabama', 'the 1,000-classroom mark', 'our P-3 pilot program', 'the gains', 'Pre-K', '75 classrooms', 'the rising demand', 'the computer science field', 'our efforts', 'computer science education', 'Alabama', 'legislation', 'the Alabama School', 'Cyber Technology', 'Engineering', 'additional funding', 'the Alabama Math and Science Teacher Education Program', 'a better pathway', 'future computer science teachers', 'Alabama', 'women', 'minorities', 'well over half', 'the population', 'the STEM professions', 'a young woman', 'the face', 'this disparity', 'the area', 'computer science', 'Arrington Harper', 'the Alabama School', 'Fine Arts', 'Birmingham', 'her ninth-grade year', 'her very first computer science class', 'Arrington', 'a recipient', 'the Aspirations', 'Computer Science Award', 'Alabama', 'an advocate', 'computer science education', 'girls', 'computer science', 'her passion', 'the gender and race gaps', 'computer science education', 'Arrington', 'numerous groups', 'parents', 'educators', 'the National Center', 'Women', 'her experiences', 'computer science', 'college', 'Arrington', 'my vision', 'education', 'our state', 'a classroom', 'her niche', 'the guidance', 'her dedicated teachers', 'her own hard work', 'this young lady', 'a very promising future', 'our students', 'the proper skills', 'education', 'high-demand jobs', 'their strong finish', 'my mission', 'the state', 'a path', 'our students', 'the workforce', 'our efforts', 'the Legislature', 'our new co-op program', 'Alabama’s Historically Black Colleges', 'Universities', 'Alabama’s HBCU students', 'careers', 'the science, technology, engineering and mathematics fields', 'a win', 'these students', 'a win', 'these colleges', 'universities', 'a win', 'our employers', 'qualified individuals', 'the work', 'their company', 'the internet', 'high speed broadband access', 'the Alabama Broadband Accessibility Act', 'broadband', 'seven counties', 'One notable example', 'Choctaw County', 'the next two years', 'more than 700 residences', 'businesses', 'access', 'high-speed internet service', 'Thanks', 'this grant program', 'rural Alabama', 'a major step', 'education', 'economic prosperity', 'the entire state', 'Alabama', 'our efforts', 'the current and future needs', 'business', 'industry', 'the Governor’s Office', 'Education', 'Workforce Transformation', 'The focus', 'our workforce development funding streams', 'the most effective workforce development programs', 'Alabamians', 'the state', 'our efforts', 'Alabama’s education system', 'our way', 'all our students', 'a quality education', 'our own story', 'My own story', 'the public schools', 'rural Wilcox County', 'high school', 'a class', '35 students', 'My surroundings', 'Auburn University', 'a whole lot', 'a class', 'a college', 'My Wilcox County upbringing', 'the smartest young people', 'bigger schools', 'larger cities', 'these challenges', 'success', 'the summer', 'my first semester', 'a week', 'campus', 'the grounds', 'my classes', 'the Auburn University Marching Band', 'Benjamin Franklin', 'success', 'My journey', 'Wilcox County', 'the heavy challenges', 'Alabama', 'success', 'that success', 'a robust economy', 'ample public safety', 'these issues', 'a reasonable increase', 'the investment', '’s', 'Almost three decades', 'Alabama', 'one change', 'our infrastructure funding', 'our neighboring states', 'their revenue', 'their transportation budgets', 'Alabama', 'motorists', 'the poor conditions', 'Alabama’s infrastructure', 'Alabama', '69 billion miles', 'our roadways', 'urban roads', 'poor condition', 'Our drivers', 'major congestion', 'our freeways', 'County governments', 'a 56-year resurfacing schedule', 'fact', 'a 15-year rate', 'Alabama', 'half', 'our more than 16,000 bridges', 'their 50-year life span', 'Bridges', 'county governments', 'schedule', 'their bridges', 'Folks', 'that’s', 'Alabama', 'a state', 'Alabama', 'nearly 3,000 traffic fatalities', 'One-third', 'deficiencies', 'our roadways', '$436 billion dollars', 'goods', 'businesses', 'our state', '’s roadways', 'The Port', 'Mobile', 'Alabama’s', 'only deep-water port', 'approximately 64 million tons', 'cargo', 'the Port', 'Alabama’s economic capability', 'our status', 'a primary industrial and agricultural hub', 'the Southeast', 'rough roads', 'the average Alabamian $507 dollars', 'additional vehicle maintenance', 'a total', '$2 billion dollars', 'a 10-cent increase', 'Alabama’s fuel tax', 'This increase', 'the next three years', 'this money', 'strong accountability measures', 'these monies', 'transportation infrastructure', 'Period', 'the charge', 'the Legislature', 'this issue', 'Representative Bill Poole', 'Senator Clyde Chambliss', 'this legislation', 'the coming weeks', 'their leadership', 'leaders', 'good points', 'money', 'the Alabama Department', 'Transportation', 'our court system', 'law enforcement agency', 'this outdated approach', 'fact', 'the budgets', 'this annual transfer', 'half', 'the court system', 'our hardworking state law enforcement officers', 'A renewed investment', 'infrastructure', 'safer roads', 'economic prosperity', 'an enhanced quality', 'life', 'the members', 'the Alabama Legislature', 'a special session', 'this critical legislation', 'this special session', 'our focus', 'this issue', 'our crumbling infrastructure system', 'the past', 'a challenge', 'every Alabamian', 'governor', 'the time', 'Rebuild Alabama', 'Another problem', 'years', 'years', 'the horrendous conditions', 'our prisons', 'the issue', 'our recruiting and retention efforts', 'Alabama', 'a federal court order', 'the state', 'roughly double the number', 'corrections officers', 'the next two years', 'the apparent issue', 'our prisons', 'federal courts', 'our own state', 'an additional $31 million dollars', 'the General Fund budget', '500 new correctional officers', 'the pay scale', 'all prison security personnel', 'their salary', 'an Alabama problem', 'an Alabama solution', 'our funds', 'the General Fund budget', 'a positive sign', 'that progress', 'Medicaid', 'the capable leadership', 'Commissioner Stephanie Azar', 'The Medicaid program', 'Alabama', 'efficiency', 'our taxpayer dollars', 'an additional $7 million dollars', 'important Mental Health programs', 'our state', 'governor', 'my power', 'Alabama', 'my General Fund budget', 'funding', '50 additional State Troopers', 'my budget', 'a 2 percent pay raise', 'all state employees', 'These men', 'women', 'merit', 'the increase', 'the additional increase', 'my General Fund budget', 'my education budget', 'more Alabamians', 'the opportunity', 'a quality education', 'My education budget', '$25 million dollars', 'our nationally-recognized First Class Pre-K program', 'This significant increase', 'the program', '193 classrooms', 'the largest investment', 'Alabama First Class Pre-K', 'date', 'Alabama', '’s youngest learners', 'Alabama’s institutions', 'higher education', 'major research contributions', 'significant revenue', 'our state', 'a major part', 'our identity', 'Alabama', 'hundreds of thousands', 'students', 'the workforce', 'their significant contributions', 'our state', 'my budget', 'an increased investment', '$75 million dollars', 'our four-year public colleges', 'universities', 'These institutions', 'the future', 'our state', 'Alabama’s teachers', 'our students', 'every step', 'their learning journeys', 'the highest paid public employees', 'our state', 'the Legislature', 'a four percent raise', 'all teachers', 'community college', 'our teachers', 'our students', 'success', 'The foundation', 'a strong future', 'all Alabamians', 'the classroom', 'our story', 'Alabama', 'the time', 'office', 'improvements', 'our state', '’s infrastructure', 'our prisons', 'our education system', 'a seed', 'opportunity', 'Alabama’s', 'a governor', 'the next eight or even 10 years', 'a governor', 'our state', 'the next century', 'the people', 'our great state', 'legislators', 'Democrats', 'republicans', 'progressives', 'conservatives', 'a better future', 'Alabama', 'our successes', 'our long-neglected issues', 'the next step', 'Alabama', 'our time', 'God', 'the great state', 'Alabama']\n"
     ]
    }
   ],
   "source": [
    "print(speech_entity_map['Alabama_SOTS.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cb6653360c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "tokens.remove(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.tokenize.word_tokenize(\"cannot can't apple-pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(nlp(\"hello world\")[:]).__module__)\n",
    "print(type(nlp(\"hello world\")[:]).__name__)\n",
    "print(type(nlp(\"hello world\")[0]).__name__)\n",
    "print(type(nlp(\"hello world\")).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
